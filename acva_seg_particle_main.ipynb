{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebba5708",
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# Copyright (c) 2025 Rong Chen (rong.chen.mail@gmail.com)\n",
    "# All rights reserved.\n",
    "# This source code is licensed under the MIT license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "#\n",
    "# Particle segmentation: development \n",
    "######\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "from itertools import product\n",
    "import random\n",
    "\n",
    "from acva_seg_particle_core import seg_particle_core\n",
    "from acva_seg_particle_core import seg_particle_3d\n",
    "from acva_toolbox import get_centered_subset, conf_to_csv, remove_image\n",
    "from acva_toolbox import hp_selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe55e5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a given f_set and configuration file, we run the analysis pipeline\n",
    "# this function will get the configuration file based on home_folder and channel_folder\n",
    "def mode_conditional_run(home_folder, channel_folder, f_set):\n",
    "    conf_file = os.path.join(home_folder, channel_folder + \"_res\", \"conf_seg_particle.csv\")\n",
    "    if os.path.isfile(conf_file):\n",
    "        param = pd.read_csv(conf_file)\n",
    "        erosionIte = int(param[\"value\"][0])\n",
    "        flatFieldSiz = int(param[\"value\"][1])\n",
    "        hatSiz = int(param[\"value\"][2])\n",
    "        valThZ = param[\"value\"][3]\n",
    "        binStrSiz = int(param[\"value\"][4])\n",
    "        blockSiz = int(param[\"value\"][5])\n",
    "        print(erosionIte, flatFieldSiz, hatSiz, valThZ, binStrSiz, blockSiz)\n",
    "\n",
    "        partial_func = partial(seg_particle_core, conf_file=conf_file)\n",
    "        with Pool() as pool:\n",
    "            pool.map(partial_func, f_set)\n",
    "        rrr = os.path.join(home_folder, channel_folder + \"_res\")\n",
    "        b_set = [os.path.join(rrr, f) for f in os.listdir(rrr) if f.endswith(\".png\")]\n",
    "        seg_particle_3d(b_set, block_size=blockSiz)\n",
    "    else:\n",
    "        print(\"Error: the configuration file does not exist.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf2719e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode_hyper_param_tuning(home_folder, channel_folder, f_subset, conf_space, rsp_limit):\n",
    "    # random sampling the conf space\n",
    "    res = []\n",
    "    n = min(rsp_limit, int(0.1 * len(conf_space)))\n",
    "    sampled = random.sample(range(len(conf_space)), n)\n",
    "    for item in sampled:\n",
    "        # prepare the configuration file\n",
    "        conf_current = conf_space[item]\n",
    "        conf_file = os.path.join(home_folder, channel_folder + '_res', \"conf_seg_particle.csv\")\n",
    "        conf_to_csv(conf_current, conf_file)\n",
    "\n",
    "        remove_image(os.path.join(home_folder, channel_folder + '_res'))\n",
    "\n",
    "        mode_conditional_run(home_folder, channel_folder, f_subset)\n",
    "        ttt = pd.read_csv(os.path.join(home_folder, channel_folder + '_res', \"all_objects.csv\"))\n",
    "        total_vol = ttt[\"volume\"].to_numpy().sum()\n",
    "        conf_current[\"U\"] = total_vol\n",
    "        res.append(conf_current)\n",
    "\n",
    "    # select a configuration\n",
    "    rrr = pd.DataFrame(res)\n",
    "    fname = os.path.join(home_folder, channel_folder + '_res', \"000_u.csv\")\n",
    "    rrr.to_csv(fname, index=False)\n",
    "    conf_selected = hp_selection(rrr)\n",
    "    print(conf_selected)\n",
    "    conf_file = os.path.join(home_folder, channel_folder + '_res', \"conf_seg_particle.csv\")\n",
    "    conf_to_csv(conf_selected, conf_file)\n",
    "\n",
    "    remove_image(os.path.join(home_folder, channel_folder + '_res'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd2eea59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\rchen_pc\\software\\acva\\data_test\\neuron_nuclei full_run\n",
      "60 40 40 1.0 7 30\n"
     ]
    }
   ],
   "source": [
    "# we use this to keep ident/format that is critical to python\n",
    "# this is useful only if we use this notebook as a main function\n",
    "program = \"main\"\n",
    "if program == \"main\":\n",
    "    random.seed(888)\n",
    "    rsp_limit = 30\n",
    "    subset_span = 5\n",
    "\n",
    "    # when we convert this to python, exp_file is an arg input\n",
    "    exp_file = \"exp_sample.csv\"\n",
    "\n",
    "    f_set = []\n",
    "    if(os.path.isfile(exp_file)):\n",
    "        prj = pd.read_csv(exp_file)\n",
    "        home_folder = prj[\"folder\"][0]\n",
    "        channel_folder = prj[\"folder\"][1]\n",
    "        data_folder = os.path.join(home_folder, channel_folder)\n",
    "        for r, _, f in os.walk(data_folder):\n",
    "            for file in f:\n",
    "                file_path = os.path.join(r, file)\n",
    "                f_set.append(file_path)\n",
    "\n",
    "        rrr = os.path.join(home_folder, channel_folder + '_res')\n",
    "        if not os.path.exists(rrr):\n",
    "            os.makedirs(rrr)\n",
    "            opMode = \"hyper_param_tuning\"\n",
    "        else:\n",
    "            # if the result folder exists, then it MUST have a conf file.\n",
    "            # create the clean result folder; remove all image files if they exist.\n",
    "            remove_image(rrr)\n",
    "            opMode = \"full_run\"\n",
    "    else:\n",
    "        print(\"Error: the experiment file does not exist. \")\n",
    "\n",
    "    print(data_folder, opMode)\n",
    "    if opMode == \"full_run\":\n",
    "        mode_conditional_run(home_folder, channel_folder, f_set)\n",
    "    elif opMode == \"hyper_param_tuning\":\n",
    "        conf_df = pd.read_csv(\"conf_seg_particle_space.csv\")\n",
    "        print(conf_df)\n",
    "        erosion_iteration = conf_df[\"start\"][0]\n",
    "        flat_field_size_range = np.arange(conf_df[\"start\"][1], conf_df[\"end\"][1] + 1, 2)\n",
    "        white_hat_size = conf_df[\"start\"][2]\n",
    "        threshold_z_range = np.arange(conf_df[\"start\"][3], conf_df[\"end\"][3] + 0.1, 0.25)\n",
    "        binary_structure_size_range = np.arange(conf_df[\"start\"][4], conf_df[\"end\"][4] + 1, 2)\n",
    "        block_size = conf_df[\"start\"][5]\n",
    "        conf_space = [{\n",
    "                \"erosion_iteration\": erosion_iteration,\n",
    "                \"flat_field_size\": f,\n",
    "                \"white_hat_size\": white_hat_size,\n",
    "                \"threshold_z\": z,\n",
    "                \"binary_structure_size\": b,\n",
    "                \"block_size\": block_size,\n",
    "            }\n",
    "            for f, z, b in product(flat_field_size_range, threshold_z_range, binary_structure_size_range)]\n",
    "\n",
    "        f_subset = get_centered_subset(f_set, span=subset_span) # different from the full run, we use a subset\n",
    "        mode_hyper_param_tuning(home_folder, channel_folder, f_subset, conf_space, rsp_limit)\n",
    "    else:\n",
    "        print(\"unknown mode\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_acva",
   "language": "python",
   "name": "env_acva"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
